---
# You don't need to edit this file, it's empty on purpose.
# Edit theme's home layout instead if you wanna make some changes
# See: https://jekyllrb.com/docs/themes/#overriding-theme-defaults
layout: home
---

# Bio

{% include identity_card.html url="me2021_redux.jpg" %}

Hi there!
I am a Research Scientist at Google DeepMind.
I am doing research on Reinforcement Learning and LLMs and also contributing to large-scale efforts including Bard, Gemini and Gemma.

Prior to that, I did my PhD at Google Brain and Inria Lille ([Scool team](https://team.inria.fr/scool/team-members/), ex-SequeL). 
I worked on Reinforcement Learning, with a focus on credit assignment and interpretability.
My advisors were [Olivier Pietquin](https://scholar.google.com/citations?user=8K8-LdwAAAAJ) and [Philippe Preux](https://scholar.google.com/citations?user=JTXxmeAAAAAJ). I also collaborated with [Matthieu Geist](https://scholar.google.com/citations?user=ectPLEUAAAAJ). 

My PhD thesis is available for consultation ([manuscript](https://drive.google.com/file/d/1tE1KEzJAiYA7NrskMd_rJejGp5sHQ_c_/view?usp=sharing), [slides](https://drive.google.com/file/d/1XIM3Jko68f70aEsog2vO5cOeT21F_oyh/view?usp=sharing)).

Prior to my PhD, I got an engineering degree in Computer Science and Applied Mathematics from Télécom Paris, and an M.Sc. in Machine Learning from École Polytechnique. I then worked for two years as a Research Engineer at [DreamQuark](https://www.dreamquark.com).

Outside of work, I make [generative art](https://aleavore.xyz) (no GANs involved for now!). I also love music, [roguelikes](https://en.wikipedia.org/wiki/Roguelike), [high-intensity interval training](https://en.wikipedia.org/wiki/High-intensity_interval_training) and spicy food.

My CV is available [online](https://ferretj.github.io/resources/CV_ferretj.pdf), and all my publications can be consulted [here](https://scholar.google.com/citations?user=uyUnqjMAAAAJ). 

# Publications

**WARM: On the Benefits of Weight Averaged Reward Models** \
Alexandre Ramé, Nino Vieillard, Léonard Hussenot, Robert Dadashi, Geoffrey Cideron, Olivier Bachem, <ins>Johan Ferret</ins> \
ICML 2024 \
\[ [paper](https://arxiv.org/abs/2401.12187) \]

**RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback** \
Harrison Lee, Samrat Phatale, Hassan Mansoor, Thomas Mesnard, <ins>Johan Ferret</ins>, Kellie Lu, Colton Bishop, Ethan Hall, Victor Carbune, Abhinav Rastogi, Sushant Prakash \
ICML 2024 \
\[ [paper](https://arxiv.org/abs/2309.00267) \]

**A Survey of Temporal Credit Assignment in Deep Reinforcement Learning** \
Eduardo Pignatelli, <ins>Johan Ferret</ins>, Matthieu Geist, Hado van Hasselt, Olivier Pietquin, Laura Toni \
TMLR 2024 \
\[ [paper](https://arxiv.org/abs/2312.01072) \]

**Factually Consistent Summarization via Reinforcement Learning with Textual Entailment Feedback** \
<ins>Johan Ferret</ins>**\***, Paul Roit**\***, Lior Shani**\***, Roee Aharoni, Geoffrey Cideron, Robert Dadashi, Matthieu Geist, Sertan Girgin, Léonard Hussenot, Orgad Keller, Nikola Momchev, Sabela Ramos, Piotr Stanczyk, Nino Vieillard, Olivier Bachem, Gal Elidan, Avinatan Hassidim, Olivier Pietquin, Idan Szpektor \
ACL 2023 \
\[ [paper](https://arxiv.org/abs/2306.00186) \| code soon! \]

**On Actions that Matter: Credit Assignment and Interpretability in Reinforcement Learning** \
<ins>Johan Ferret</ins> \
PhD thesis \
\[ [manuscript](https://drive.google.com/file/d/1tE1KEzJAiYA7NrskMd_rJejGp5sHQ_c_/view?usp=sharing) \| [slides](https://drive.google.com/file/d/1XIM3Jko68f70aEsog2vO5cOeT21F_oyh/view?usp=sharing) \]

**Lazy-MDPs: Towards Interpretable Reinforcement Learning by Learning When to Act** \
<ins>Johan Ferret</ins>**\***, Alexis Jacq**\***, Olivier Pietquin, Matthieu Geist \
AAMAS 2022 \
\[ [paper](https://arxiv.org/abs/2203.08542) \| code soon! \]

**There is no Turning Back: A Self-Supervised Approach to Reversibility-Aware Reinforcement Learning** \
<ins>Johan Ferret</ins>**\***, Nathan Grinsztajn**\***, Olivier Pietquin, Philippe Preux, Matthieu Geist \
NeurIPS 2021 \
\[ [paper](https://arxiv.org/abs/2106.04480) \| [blog post](https://ai.googleblog.com/2021/11/self-supervised-reversibility-aware.html) \| [slides](https://drive.google.com/file/d/11gXunD8wRkIjF90qTUJkXRJYgAaycFxi/view?usp=sharing) \| [code](https://github.com/nathangrinsztajn/NoTurningBack) \]

**Self-Imitation Advantage Learning** \
<ins>Johan Ferret</ins>, Olivier Pietquin, Matthieu Geist \
AAMAS 2021 \
\[ [paper](https://arxiv.org/abs/2012.11989) \| [slides](https://drive.google.com/file/d/12JGykEt3tA7tEn0MZ5eR02mXY-54zF9o/view?usp=sharing) \| [code](https://github.com/google-research/google-research/tree/master/sail_rl) \]

**Adversarially Guided Actor-Critic** \
<ins>Johan Ferret</ins>**\***, Yannis Flet-Berliac**\***, Olivier Pietquin, Philippe Preux, Matthieu Geist \
ICLR 2021 \
\[ [paper](https://arxiv.org/abs/2102.04376) \| [slides](https://drive.google.com/file/d/13cYtQ0MxmCYSZ-Jcm44_ClnHWPsfwO8b/view?usp=sharing) \| [video](https://slideslive.com/38954238/adversarially-guided-actorcritic?ref=speaker-24735-latest) \| [code](https://github.com/yfletberliac/adversarially-guided-actor-critic) \]

**Self-Attentional Credit Assignment for Transfer in Reinforcement Learning** \
<ins>Johan Ferret</ins>, Raphaël Marinier, Matthieu Geist, Olivier Pietquin \
IJCAI 2020 \
\[ [paper](https://arxiv.org/abs/1907.08027) \| [slides](https://drive.google.com/file/d/1e4-ypq84m3SIqjA9BqUvuM4P4psO9Laq/view?usp=sharing) \| [video](https://drive.google.com/file/d/1_U-XsCY01b_46CFiPkC5A4Z2VN0by5KE/view?usp=sharing) \]

# Preprints

**WARP: On the Benefits of Weight Averaged Rewarded Policies** \
Alexandre Ramé, <ins>Johan Ferret</ins>, Nino Vieillard, Robert Dadashi, Léonard Hussenot, Pierre-Louis Cedoz, Pier Giuseppe Sessa, Sertan Girgin, Arthur Douillard, Olivier Bachem \
arxiv preprint \
\[ [paper](https://arxiv.org/abs/2406.16768v1) \]

**BOND: Aligning LLMs with Best-of-N Distillation** \
Pier Giuseppe Sessa, Robert Dadashi, Léonard Hussenot, <ins>Johan Ferret</ins>, Nino Vieillard, Alexandre Ramé, Bobak Shariari, Sarah Perrin, Abe Friesen, Geoffrey Cideron, Sertan Girgin, Piotr Stanczyk, Andrea Michi, Danila Sinopalnikov, Sabela Ramos, Amélie Héliou, Aliaksei Severyn, Matt Hoffman, Nikola Momchev, Olivier Bachem \
arxiv preprint \
\[ [paper](https://arxiv.org/abs/2407.14622v1) \]

**Conditioned Language Policy: A General Framework for Steerable Multi-Objective Finetuning** \
Kaiwen Wang, Rahul Kidambi, Ryan Sullivan, Alekh Agarwal, Christoph Dann, Andrea Michi, Marco Gelmi, Yunxuan Li, Raghav Gupta, Avinava Dubey, Alexandre Ramé, <ins>Johan Ferret</ins>, Geoffrey Cideron, Le Hou, Hongkun Yu, Amr Ahmed, Aranyak Mehta, Léonard Hussenot, Olivier Bachem, Edouard Leurent \
arxiv preprint \
\[ [paper](https://arxiv.org/abs/2407.15762) \]

**RecurrentGemma: Moving Past Transformers for Efficient Open Language Models** \
Griffin Team, <ins>RLHF Team</ins>, Gemma Team \
Technical report \
\[ [paper](https://arxiv.org/abs/2404.07839) \]

**Gemma: Open Models Based on Gemini Research and Technology** \
Gemma Team \
Technical report \
\[ [paper](https://arxiv.org/abs/2403.08295) \]

**Direct Language Model Alignment from Online AI Feedback** \
Shangmin Guo, Biao Zhang, Tianlin Liu, Tianqi Liu, Misha Khalman, Felipe Llinares, Alexandre Ramé, Thomas Mesnard, Yao Zhao, Bilal Piot, <ins>Johan Ferret</ins>, Mathieu Blondel \
arxiv preprint \
\[ [paper](https://arxiv.org/abs/2402.04792) \]

**Gemini: A Family of Highly Capable Multimodal Models** \
Gemini Team \
Technical report \
\[ [paper](https://arxiv.org/abs/2312.11805) \]

**Acme: A Research Framework for Distributed Reinforcement Learning** \
Acme Team \
arxiv preprint \
\[ [paper](https://arxiv.org/abs/2006.00979) \| [colab](https://github.com/deepmind/acme/blob/master/examples/quickstart.ipynb) \| [code](https://dpmd.ai/acme-github) \]

# Workshops

**Assessing the Zero-Shot Capabilities of LLMs for Action Evaluation in RL** \
Eduardo Pignatelli, <ins>Johan Ferret</ins>, Davide Paglieri, Samuel Coward, Tim Rocktäschel, Edward Grefenstette, Laura Toni \
AutoRL workshop, ICML 2024 \
\[ [paper](https://openreview.net/forum?id=MFw8K5705I) \]

**More Efficient Exploration with Symbolic Priors on Action Sequence Equivalence** \
Nathan Grinsztajn, Toby Johnstone, <ins>Johan Ferret</ins>, Philippe Preux \
Deep Reinforcement Learning workshop, NeurIPS 2022 \
\[ [paper](https://arxiv.org/abs/2110.10632) \]

**Offline Credit Assignment in Deep Reinforcement Learning with Hindsight Discriminator Networks** \
<ins>Johan Ferret</ins>, Olivier Pietquin, Matthieu Geist \
EWRL 2022 \
\[ [paper](https://drive.google.com/file/d/1EG4EpCpjzrI850ROwEutIcsCIu5isxlD/view?usp=sharing) \]

**Credit Assignment as a Proxy for Transfer in Reinforcement Learning** \
<ins>Johan Ferret</ins>, Raphaël Marinier, Matthieu Geist, Olivier Pietquin \
Learning Transferable Skills workshop, NeurIPS 2019 (oral) \
\[ [paper](https://arxiv.org/abs/1907.08027) \]
