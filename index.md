---
# You don't need to edit this file, it's empty on purpose.
# Edit theme's home layout instead if you wanna make some changes
# See: https://jekyllrb.com/docs/themes/#overriding-theme-defaults
layout: home
---

# Bio

{% include identity_card.html url="me2021_redux.jpg" %}

Hi there!
I am a Research Scientist at Google DeepMind.
I am doing research on Reinforcement Learning and LLMs and also contributing to large-scale efforts including Bard, Gemini and Gemma.

Prior to that, I did my PhD at Google Brain and Inria Lille ([Scool team](https://team.inria.fr/scool/team-members/), ex-SequeL). 
I worked on Reinforcement Learning, with a focus on credit assignment and interpretability.
My advisors were [Olivier Pietquin](https://scholar.google.com/citations?user=8K8-LdwAAAAJ) and [Philippe Preux](https://scholar.google.com/citations?user=JTXxmeAAAAAJ). I also collaborated with [Matthieu Geist](https://scholar.google.com/citations?user=ectPLEUAAAAJ). 

My PhD thesis is available for consultation ([manuscript](https://drive.google.com/file/d/1tE1KEzJAiYA7NrskMd_rJejGp5sHQ_c_/view?usp=sharing), [slides](https://drive.google.com/file/d/1XIM3Jko68f70aEsog2vO5cOeT21F_oyh/view?usp=sharing)).

Prior to my PhD, I got an engineering degree in Computer Science and Applied Mathematics from Télécom Paris, and an M.Sc. in Machine Learning from École Polytechnique. I then worked for two years as a Research Engineer at [DreamQuark](https://www.dreamquark.com).

Outside of work, I make [generative art](https://aleavore.xyz) (no GANs involved for now!). I also love music, [roguelikes](https://en.wikipedia.org/wiki/Roguelike), [high-intensity interval training](https://en.wikipedia.org/wiki/High-intensity_interval_training) and spicy food.

My CV is available [online](https://ferretj.github.io/resources/CV_ferretj.pdf), and all my publications can be consulted [here](https://scholar.google.com/citations?user=uyUnqjMAAAAJ). 

# Publications

**A Survey of Temporal Credit Assignment in Deep Reinforcement Learning** \
Eduardo Pignatelli, <ins>Johan Ferret</ins>, Matthieu Geist, Hado van Hasselt, Olivier Pietquin, Laura Toni \
TMLR 2024 \
\[ [paper](https://arxiv.org/abs/2312.01072) \]

**Factually Consistent Summarization via Reinforcement Learning with Textual Entailment Feedback** \
<ins>Johan Ferret</ins>**\***, Paul Roit**\***, Lior Shani**\***, Roee Aharoni, Geoffrey Cideron, Robert Dadashi, Matthieu Geist, Sertan Girgin, Léonard Hussenot, Orgad Keller, Nikola Momchev, Sabela Ramos, Piotr Stanczyk, Nino Vieillard, Olivier Bachem, Gal Elidan, Avinatan Hassidim, Olivier Pietquin, Idan Szpektor \
ACL 2023 \
\[ [paper](https://arxiv.org/abs/2306.00186) \| code soon! \]

**On Actions that Matter: Credit Assignment and Interpretability in Reinforcement Learning** \
<ins>Johan Ferret</ins> \
PhD thesis \
\[ [manuscript](https://drive.google.com/file/d/1tE1KEzJAiYA7NrskMd_rJejGp5sHQ_c_/view?usp=sharing) \| [slides](https://drive.google.com/file/d/1XIM3Jko68f70aEsog2vO5cOeT21F_oyh/view?usp=sharing) \]

**Lazy-MDPs: Towards Interpretable Reinforcement Learning by Learning When to Act** \
<ins>Johan Ferret</ins>**\***, Alexis Jacq**\***, Olivier Pietquin, Matthieu Geist \
AAMAS 2022 \
\[ [paper](https://arxiv.org/abs/2203.08542) \| code soon! \]

**There is no Turning Back: A Self-Supervised Approach to Reversibility-Aware Reinforcement Learning** \
<ins>Johan Ferret</ins>**\***, Nathan Grinsztajn**\***, Olivier Pietquin, Philippe Preux, Matthieu Geist \
NeurIPS 2021 \
\[ [paper](https://arxiv.org/abs/2106.04480) \| [blog post](https://ai.googleblog.com/2021/11/self-supervised-reversibility-aware.html) \| [slides](https://drive.google.com/file/d/11gXunD8wRkIjF90qTUJkXRJYgAaycFxi/view?usp=sharing) \| [code](https://github.com/nathangrinsztajn/NoTurningBack) \]

**Self-Imitation Advantage Learning** \
<ins>Johan Ferret</ins>, Olivier Pietquin, Matthieu Geist \
AAMAS 2021 \
\[ [paper](https://arxiv.org/abs/2012.11989) \| [slides](https://drive.google.com/file/d/12JGykEt3tA7tEn0MZ5eR02mXY-54zF9o/view?usp=sharing) \| [code](https://github.com/google-research/google-research/tree/master/sail_rl) \]

**Adversarially Guided Actor-Critic** \
<ins>Johan Ferret</ins>**\***, Yannis Flet-Berliac**\***, Olivier Pietquin, Philippe Preux, Matthieu Geist \
ICLR 2021 \
\[ [paper](https://arxiv.org/abs/2102.04376) \| [slides](https://drive.google.com/file/d/13cYtQ0MxmCYSZ-Jcm44_ClnHWPsfwO8b/view?usp=sharing) \| [video](https://slideslive.com/38954238/adversarially-guided-actorcritic?ref=speaker-24735-latest) \| [code](https://github.com/yfletberliac/adversarially-guided-actor-critic) \]

**Self-Attentional Credit Assignment for Transfer in Reinforcement Learning** \
<ins>Johan Ferret</ins>, Raphaël Marinier, Matthieu Geist, Olivier Pietquin \
IJCAI 2020 \
\[ [paper](https://arxiv.org/abs/1907.08027) \| [slides](https://drive.google.com/file/d/1e4-ypq84m3SIqjA9BqUvuM4P4psO9Laq/view?usp=sharing) \| [video](https://drive.google.com/file/d/1_U-XsCY01b_46CFiPkC5A4Z2VN0by5KE/view?usp=sharing) \]

# Preprints

**RecurrentGemma: Moving Past Transformers for Efficient Open Language Models** \
Griffin Team, <ins>RLHF Team</ins>, Gemma Team \
Technical report \
\[ [paper](https://arxiv.org/abs/2404.07839) \]

**Gemma: Open Models Based on Gemini Research and Technology** \
Gemma Team \
Technical report \
\[ [paper](https://arxiv.org/abs/2403.08295) \]

**Direct Language Model Alignment from Online AI Feedback** \
Shangmin Guo, Biao Zhang, Tianlin Liu, Tianqi Liu, Misha Khalman, Felipe Llinares, Alexandre Ramé, Thomas Mesnard, Yao Zhao, Bilal Piot, <ins>Johan Ferret</ins>, Mathieu Blondel \
arxiv preprint \
\[ [paper](https://arxiv.org/abs/2402.04792) \]

**WARM: On the Benefits of Weight Averaged Reward Models** \
Alexandre Ramé, Nino Vieillard, Léonard Hussenot, Robert Dadashi, Geoffrey Cideron, Olivier Bachem, <ins>Johan Ferret</ins> \
arxiv preprint \
\[ [paper](https://arxiv.org/abs/2401.12187) \]

**Gemini: A Family of Highly Capable Multimodal Models** \
Gemini Team \
Technical report \
\[ [paper](https://arxiv.org/abs/2312.11805) \]

**RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback** \
Harrison Lee, Samrat Phatale, Hassan Mansoor, Thomas Mesnard, <ins>Johan Ferret</ins>, Kellie Lu, Colton Bishop, Ethan Hall, Victor Carbune, Abhinav Rastogi, Sushant Prakash \
arxiv preprint \
\[ [paper](https://arxiv.org/abs/2309.00267) \]

**Acme: A Research Framework for Distributed Reinforcement Learning** \
Matthew Hoffman, Bobak Shahriari, John Aslanides, Gabriel Barth-Maron, Nikola Momchev, Danila Sinopalnikov, Piotr Stańczyk, Sabela Ramos, Anton Raichuk, Damien Vincent, Léonard Hussenot, Robert Dadashi, Gabriel Dulac-Arnold, Manu Orsini, Alexis Jacq, <ins>Johan Ferret</ins>, Nino Vieillard, Seyed Kamyar Seyed Ghasemipour, Sertan Girgin, Olivier Pietquin, Feryal Behbahani, Tamara Norman, Abbas Abdolmaleki, Albin Cassirer, Fan Yang, Kate Baumli, Sarah Henderson, Abe Friesen, Ruba Haroun, Alex Novikov, Sergio Gómez Colmenarejo, Serkan Cabi, Caglar Gulcehre, Tom Le Paine, Srivatsan Srinivasan, Andrew Cowie, Ziyu Wang, Bilal Piot, Nando de Freitas \
arxiv preprint \
\[ [paper](https://arxiv.org/abs/2006.00979) \| [colab](https://github.com/deepmind/acme/blob/master/examples/quickstart.ipynb) \| [code](https://dpmd.ai/acme-github) \]

# Workshops

**More Efficient Exploration with Symbolic Priors on Action Sequence Equivalence** \
Nathan Grinsztajn, Toby Johnstone, <ins>Johan Ferret</ins>, Philippe Preux \
Deep Reinforcement Learning workshop, NeurIPS 2022 \
\[ [paper](https://arxiv.org/abs/2110.10632) \]

**Offline Credit Assignment in Deep Reinforcement Learning with Hindsight Discriminator Networks** \
<ins>Johan Ferret</ins>, Olivier Pietquin, Matthieu Geist \
EWRL 2022 \
\[ [paper](https://drive.google.com/file/d/1EG4EpCpjzrI850ROwEutIcsCIu5isxlD/view?usp=sharing) \]

**Credit Assignment as a Proxy for Transfer in Reinforcement Learning** \
<ins>Johan Ferret</ins>, Raphaël Marinier, Matthieu Geist, Olivier Pietquin \
Learning Transferable Skills workshop, NeurIPS 2019 (oral) \
\[ [paper](https://arxiv.org/abs/1907.08027) \]
