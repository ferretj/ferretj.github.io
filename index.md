---
# You don't need to edit this file, it's empty on purpose.
# Edit theme's home layout instead if you wanna make some changes
# See: https://jekyllrb.com/docs/themes/#overriding-theme-defaults
layout: home
---

# Bio

{% include identity_card.html url="me2021_redux.jpg" %}

Hi there!
I am a Research Scientist at Google Brain.
I am researching novel Deep Reinforcement Learning algorithms.

Prior to that, I did my PhD at Google Brain and Inria Lille ([Scool team](https://team.inria.fr/scool/team-members/), ex-SequeL). 
I worked on Deep Reinforcement Learning, with a focus on credit assignment and interpretability.
My advisors were [Olivier Pietquin](https://scholar.google.com/citations?user=8K8-LdwAAAAJ) and [Philippe Preux](https://scholar.google.com/citations?user=JTXxmeAAAAAJ). I also collaborated with [Matthieu Geist](https://scholar.google.com/citations?user=ectPLEUAAAAJ). 

My PhD thesis is available for consultation ([manuscript](https://drive.google.com/file/d/1tE1KEzJAiYA7NrskMd_rJejGp5sHQ_c_/view?usp=sharing), [slides](https://drive.google.com/file/d/1XIM3Jko68f70aEsog2vO5cOeT21F_oyh/view?usp=sharing)).

Prior to my PhD, I got an engineering degree in Computer Science and Applied Mathematics from Télécom Paris, and an M.Sc. in Machine Learning from École Polytechnique. I then worked for two years as a Research Engineer at [DreamQuark](https://www.dreamquark.com).

Outside of work, I make [generative art](https://aleavore.xyz) (no GANs involved for now!). I also love music, [roguelikes](https://en.wikipedia.org/wiki/Roguelike), [high-intensity interval training](https://en.wikipedia.org/wiki/High-intensity_interval_training) and spicy food.

My CV is available [online](https://ferretj.github.io/resources/CV_ferretj.pdf), and all my publications can be consulted [here](https://scholar.google.com/citations?user=uyUnqjMAAAAJ). 

# Publications

**On Actions that Matter: Credit Assignment and Interpretability in Reinforcement Learning** \
<ins>Johan Ferret</ins> \
PhD thesis \
\[ [manuscript](https://drive.google.com/file/d/1tE1KEzJAiYA7NrskMd_rJejGp5sHQ_c_/view?usp=sharing) \| [slides](https://drive.google.com/file/d/1XIM3Jko68f70aEsog2vO5cOeT21F_oyh/view?usp=sharing) \]

**Lazy-MDPs: Towards Interpretable RL by Learning When to Act** \
<ins>Johan Ferret</ins>**\***, Alexis Jacq**\***, Olivier Pietquin, Matthieu Geist \
AAMAS 2022 \
\[ [paper](https://arxiv.org/abs/2203.08542) \| code soon! \]

**There is no Turning Back: A Self-Supervised Approach to Reversibility-Aware Reinforcement Learning** \
<ins>Johan Ferret</ins>**\***, Nathan Grinsztajn**\***, Olivier Pietquin, Philippe Preux, Matthieu Geist \
NeurIPS 2021 \
\[ [paper](https://arxiv.org/abs/2106.04480) \| [blog post](https://ai.googleblog.com/2021/11/self-supervised-reversibility-aware.html) \| [slides](https://drive.google.com/file/d/11gXunD8wRkIjF90qTUJkXRJYgAaycFxi/view?usp=sharing) \| [code](https://github.com/nathangrinsztajn/NoTurningBack) \]

**Self-Imitation Advantage Learning** \
<ins>Johan Ferret</ins>, Olivier Pietquin, Matthieu Geist \
AAMAS 2021 \
\[ [paper](https://arxiv.org/abs/2012.11989) \| [slides](https://drive.google.com/file/d/12JGykEt3tA7tEn0MZ5eR02mXY-54zF9o/view?usp=sharing) \| [code](https://github.com/google-research/google-research/tree/master/sail_rl) \]

**Adversarially Guided Actor-Critic** \
<ins>Johan Ferret</ins>**\***, Yannis Flet-Berliac**\***, Olivier Pietquin, Philippe Preux, Matthieu Geist \
ICLR 2021 \
\[ [paper](https://arxiv.org/abs/2102.04376) \| [slides](https://drive.google.com/file/d/13cYtQ0MxmCYSZ-Jcm44_ClnHWPsfwO8b/view?usp=sharing) \| [video](https://slideslive.com/38954238/adversarially-guided-actorcritic?ref=speaker-24735-latest) \| [code](https://github.com/yfletberliac/adversarially-guided-actor-critic) \]

**Self-Attentional Credit Assignment for Transfer in Reinforcement Learning** \
<ins>Johan Ferret</ins>, Raphaël Marinier, Matthieu Geist, Olivier Pietquin \
IJCAI 2020 \
\[ [paper](https://arxiv.org/abs/1907.08027) \| [slides](https://drive.google.com/file/d/1e4-ypq84m3SIqjA9BqUvuM4P4psO9Laq/view?usp=sharing) \| [video](https://drive.google.com/file/d/1_U-XsCY01b_46CFiPkC5A4Z2VN0by5KE/view?usp=sharing) \]

# Preprints

**Acme: A Research Framework for Distributed Reinforcement Learning** \
Matthew Hoffman, Bobak Shahriari, ..., <ins>Johan Ferret</ins>, ..., Nando de Freitas \
arxiv preprint \
\[ [paper](https://arxiv.org/abs/2006.00979) \| [colab](https://github.com/deepmind/acme/blob/master/examples/quickstart.ipynb) \| [code](https://dpmd.ai/acme-github) \]

**More Efficient Exploration with Symbolic Priors on Action Sequence Equivalence** \
Toby Johnstone, Nathan Grinsztajn, <ins>Johan Ferret</ins>, Philippe Preux \
arxiv preprint \
\[ [paper](https://arxiv.org/abs/2110.10632) \]

# Workshops

**Offline Credit Assignment in Deep Reinforcement Learning with Hindsight Discriminator Networks** \
<ins>Johan Ferret</ins>, Olivier Pietquin, Matthieu Geist \
EWRL 2022 \
\[ [paper](https://drive.google.com/file/d/1EG4EpCpjzrI850ROwEutIcsCIu5isxlD/view?usp=sharing) \]

**Credit Assignment as a Proxy for Transfer in Reinforcement Learning** \
<ins>Johan Ferret</ins>, Raphaël Marinier, Matthieu Geist, Olivier Pietquin \
Learning Transferable Skills workshop, NeurIPS 2019 (oral) \
\[ [paper](https://arxiv.org/abs/1907.08027) \]
